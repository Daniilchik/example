Subject: [PATCH] test
---
Index: hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/s3/multipart/S3ExpiredMultipartUploadsAbortRequest.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/s3/multipart/S3ExpiredMultipartUploadsAbortRequest.java b/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/s3/multipart/S3ExpiredMultipartUploadsAbortRequest.java
--- a/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/s3/multipart/S3ExpiredMultipartUploadsAbortRequest.java	(revision 21d30a840ad081696b788bc43eac9bc8b52bc3ff)
+++ b/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/s3/multipart/S3ExpiredMultipartUploadsAbortRequest.java	(date 1763360811269)
@@ -32,6 +32,7 @@
 import org.apache.hadoop.ozone.om.helpers.OmMultipartAbortInfo;
 import org.apache.hadoop.ozone.om.helpers.OmMultipartKeyInfo;
 import org.apache.hadoop.ozone.om.helpers.OmMultipartUpload;
+import org.apache.hadoop.ozone.om.helpers.QuotaUtil;
 import org.apache.hadoop.ozone.om.lock.OMLockDetails;
 import org.apache.hadoop.ozone.om.request.key.OMKeyRequest;
 import org.apache.hadoop.ozone.om.request.util.OMMultipartUploadUtils;
@@ -275,13 +276,11 @@
           // When abort uploaded key, we need to subtract the PartKey length
           // from the volume usedBytes.
           long quotaReleased = 0;
-          int keyFactor = omMultipartKeyInfo.getReplicationConfig()
-              .getRequiredNodes();
-          for (PartKeyInfo iterPartKeyInfo : omMultipartKeyInfo.
-              getPartKeyInfoMap()) {
-            quotaReleased +=
-                iterPartKeyInfo.getPartKeyInfo().getDataSize() * keyFactor;
-          }
+            for (PartKeyInfo iterPartKeyInfo : omMultipartKeyInfo.getPartKeyInfoMap()) {
+              quotaReleased += QuotaUtil.getReplicatedSize(
+                      iterPartKeyInfo.getPartKeyInfo().getDataSize(),
+                      omMultipartKeyInfo.getReplicationConfig());
+            }
           omBucketInfo.incrUsedBytes(-quotaReleased);
 
           OmMultipartAbortInfo omMultipartAbortInfo =
Index: hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/om/request/s3/multipart/TestS3ExpiredMultipartUploadsAbortRequest.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/om/request/s3/multipart/TestS3ExpiredMultipartUploadsAbortRequest.java b/hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/om/request/s3/multipart/TestS3ExpiredMultipartUploadsAbortRequest.java
--- a/hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/om/request/s3/multipart/TestS3ExpiredMultipartUploadsAbortRequest.java	(revision 21d30a840ad081696b788bc43eac9bc8b52bc3ff)
+++ b/hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/om/request/s3/multipart/TestS3ExpiredMultipartUploadsAbortRequest.java	(date 1763360876685)
@@ -35,6 +35,7 @@
     .Status;
 import org.apache.hadoop.ozone.om.helpers.BucketLayout;
 import org.apache.hadoop.ozone.om.helpers.OmKeyInfo;
+import org.apache.hadoop.ozone.om.helpers.OmBucketInfo;
 import org.apache.hadoop.ozone.om.helpers.OmMultipartKeyInfo;
 import org.apache.hadoop.ozone.om.helpers.WithObjectID;
 import org.apache.hadoop.ozone.om.request.util.OMMultipartUploadUtils;
@@ -310,6 +311,48 @@
         metrics.getNumExpiredMPUPartsAborted());
   }
 
+  /**
+   * Verify that aborting expired MPUs does not make bucket usedBytes negative.
+   */
+  @ParameterizedTest
+  @MethodSource("bucketLayouts")
+  public void testAbortExpiredMPUsDoesNotMakeUsedBytesNegative(
+          BucketLayout buckLayout) throws Exception {
+    this.bucketLayout = buckLayout;
+
+    final String volumeName = UUID.randomUUID().toString();
+    final String bucketName = UUID.randomUUID().toString();
+    final String keyName = UUID.randomUUID().toString();
+
+    OMRequestTestUtils.addVolumeAndBucketToDB(volumeName, bucketName,
+            omMetadataManager, getBucketLayout());
+
+    final int numMPUs = 1;
+    final int numParts = 3;
+
+    List<String> mpuKeys = createMPUs(volumeName, bucketName, keyName,
+            numMPUs, numParts, getBucketLayout());
+
+    String bucketKey =
+            omMetadataManager.getBucketKey(volumeName, bucketName);
+    OmBucketInfo bucketInfoBefore =
+            omMetadataManager.getBucketTable().get(bucketKey);
+    long usedBytesBefore = bucketInfoBefore.getUsedBytes();
+
+    Assertions.assertTrue(usedBytesBefore > 0,
+            "Expected bucket usedBytes to be > 0 before aborting expired MPUs");
+
+    abortExpiredMPUsFromCache(volumeName, bucketName, mpuKeys);
+    OmBucketInfo bucketInfoAfter =
+            omMetadataManager.getBucketTable().get(bucketKey);
+    long usedBytesAfter = bucketInfoAfter.getUsedBytes();
+
+    Assertions.assertEquals(0L, usedBytesAfter,
+            "Bucket usedBytes should be 0 after aborting expired MPUs");
+    Assertions.assertTrue(usedBytesAfter >= 0,
+            "Bucket usedBytes must not be negative after aborting expired MPUs");
+  }
+
   /**
    * Constructs a new {@link S3ExpiredMultipartUploadsAbortRequest} objects,
    * and calls its {@link S3ExpiredMultipartUploadsAbortRequest#preExecute}
@@ -481,7 +524,7 @@
         // Add key to open key table to be used in MPU commit processing
         OmKeyInfo omKeyInfo = OMRequestTestUtils.createOmKeyInfo(volume,
             bucket, keyName, HddsProtos.ReplicationType.RATIS,
-            HddsProtos.ReplicationFactor.ONE, parentID + j, parentID,
+            HddsProtos.ReplicationFactor.THREE, parentID + j, parentID,
             trxnLogIndex, Time.now(), true);
         String fileName = OzoneFSUtils.getFileName(keyName);
         OMRequestTestUtils.addFileToKeyTable(true, false,
@@ -563,7 +606,7 @@
         OMRequestTestUtils.addKeyToTable(
             true, true,
             volume, bucket, keyName, clientID, HddsProtos.ReplicationType.RATIS,
-            HddsProtos.ReplicationFactor.ONE, omMetadataManager);
+            HddsProtos.ReplicationFactor.THREE, omMetadataManager);
 
         OMClientResponse commitResponse =
             s3MultipartUploadCommitPartRequest.validateAndUpdateCache(
